{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, gc, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'source')))\n",
    "from HMixNetTorch import HMixNet, seed_everything\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb910ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.abspath('data')\n",
    "path_res  = os.path.abspath('results')\n",
    "metrics = ['RMSP', 'RMD', 'R2']\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['epilepsy', 'cd4', 'bolus', 'owls', 'fruits']\n",
    "optimizer = 'Adam'\n",
    "learning_rates = [0.01, 0.001]\n",
    "batch_sizes = [32, 16]\n",
    "num_nodes_list = [[8,8], [4,4]]\n",
    "activation = torch.nn.LeakyReLU()\n",
    "max_epochs = 200\n",
    "patience = 10\n",
    "sig2u_init = 0.8\n",
    "sig2e_init = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7414ae",
   "metadata": {},
   "source": [
    "### Gaussian-NN(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "model_name = 'GNN-M'\n",
    "# ---------------------------------\n",
    "is_conditional = False\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_nodes in num_nodes_list:\n",
    "            experiment = f'lr{learning_rate}-batch{batch_size}-nodes{num_nodes[0]}'\n",
    "            results = {metric:np.zeros((n_folds, len(data_names))) for metric in metrics+['time']}\n",
    "            for data_number, data_name in enumerate(data_names):\n",
    "                data = pd.read_csv(f'{path_data}/{data_name}-prep.csv', dtype='float32', engine='pyarrow')        \n",
    "                n_clusters = np.unique(data['id']).shape[0]\n",
    "                n_features = 1+max([int(col_name[1:]) if 'x' in col_name else 0 for col_name in data.columns])\n",
    "                for test_fold in tqdm(range(n_folds), desc=data_name):\n",
    "                    valid_fold = (test_fold+1)//n_folds\n",
    "                    data_dict = {\n",
    "                        'train':data[-data['fold'].isin([valid_fold, test_fold])],\n",
    "                        'valid':data[data['fold'] == valid_fold],\n",
    "                        'test' :data[data['fold'] == test_fold],\n",
    "                    }\n",
    "                    for subset_name, subset in data_dict.items():\n",
    "                        z = np.array(subset['id'], dtype=np.int32)\n",
    "                        globals()[f'X_{subset_name}'] = np.array(subset[[f'x{i}' for i in range(n_features)]], dtype=np.float32)\n",
    "                        globals()[f'Z_{subset_name}'] = np.zeros((len(z), n_clusters), dtype=np.float32)\n",
    "                        globals()[f'Z_{subset_name}'][np.arange(len(z)), z] = 1\n",
    "                        globals()[f'y_{subset_name}'] = np.array(subset['y'], dtype=np.float32).reshape(-1,1)\n",
    "                    torch.cuda.empty_cache(); gc.collect()\n",
    "                    seed_everything()\n",
    "                    M = HMixNet(n_clusters, n_features, num_nodes, activation, device=device)            \n",
    "                    start_time = time.time()\n",
    "                    M.train_clik([np.log(y_train+0.5), X_train, Z_train], [np.log(y_valid+0.5), X_valid, Z_valid], is_conditional,\n",
    "                            optimizer, learning_rate, batch_size, max_epochs, patience, sig2e_init)\n",
    "                    computing_time = time.time() - start_time\n",
    "                    y_pred = M.predict(X_test)\n",
    "                    if data_name == 'owls':\n",
    "                        offset_test = np.array(data_dict['test']['offset']).flatten()\n",
    "                        y_pred = y_pred * offset_test\n",
    "                        y_test = y_test * offset_test\n",
    "                        y_train = y_train * np.array(data_dict['train']['offset']).flatten()\n",
    "                    temp_results = compute_metrics(y_test, y_pred, np.mean(y_train), metrics)\n",
    "                    for metric in metrics:\n",
    "                        results[metric][test_fold, data_number] = temp_results[metric]\n",
    "                    results['time'][test_fold, data_number] = computing_time\n",
    "                    del M; gc.collect()\n",
    "            for metric in metrics+['time']:\n",
    "                pd.DataFrame(results[metric], columns=data_names).to_csv(f'{path_res}/{model_name}-{metric}-{experiment}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2697174",
   "metadata": {},
   "source": [
    "### Gaussian-NN(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "model_name = 'GNN-C'\n",
    "# ---------------------------------\n",
    "is_conditional = True\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_nodes in num_nodes_list:\n",
    "            experiment = f'lr{learning_rate}-batch{batch_size}-nodes{num_nodes[0]}'\n",
    "            results = {metric:np.zeros((n_folds, len(data_names))) for metric in metrics+['time']}\n",
    "            for data_number, data_name in enumerate(data_names):\n",
    "                data = pd.read_csv(f'{path_data}/{data_name}-prep.csv', dtype='float32', engine='pyarrow')        \n",
    "                n_clusters = np.unique(data['id']).shape[0]\n",
    "                n_features = 1+max([int(col_name[1:]) if 'x' in col_name else 0 for col_name in data.columns])\n",
    "                for test_fold in tqdm(range(n_folds), desc=data_name):\n",
    "                    valid_fold = (test_fold+1)//n_folds\n",
    "                    data_dict = {\n",
    "                        'train':data[-data['fold'].isin([valid_fold, test_fold])],\n",
    "                        'valid':data[data['fold'] == valid_fold],\n",
    "                        'test' :data[data['fold'] == test_fold],\n",
    "                    }\n",
    "                    for subset_name, subset in data_dict.items():\n",
    "                        z = np.array(subset['id'], dtype=np.int32)\n",
    "                        globals()[f'X_{subset_name}'] = np.array(subset[[f'x{i}' for i in range(n_features)]], dtype=np.float32)\n",
    "                        globals()[f'Z_{subset_name}'] = np.zeros((len(z), n_clusters), dtype=np.float32)\n",
    "                        globals()[f'Z_{subset_name}'][np.arange(len(z)), z] = 1\n",
    "                        globals()[f'y_{subset_name}'] = np.array(subset['y'], dtype=np.float32).reshape(-1,1)\n",
    "                    torch.cuda.empty_cache(); gc.collect()\n",
    "                    seed_everything()\n",
    "                    M = HMixNet(n_clusters, n_features, num_nodes, activation, device=device)            \n",
    "                    start_time = time.time()\n",
    "                    M.train_clik([np.log(y_train+0.5), X_train, Z_train], [np.log(y_valid+0.5), X_valid, Z_valid], is_conditional,\n",
    "                            optimizer, learning_rate, batch_size, max_epochs, patience, sig2e_init)\n",
    "                    computing_time = time.time() - start_time\n",
    "                    y_pred = M.predict(X_test, Z_test)\n",
    "                    if data_name == 'owls':\n",
    "                        offset_test = np.array(data_dict['test']['offset']).flatten()\n",
    "                        y_pred = y_pred * offset_test\n",
    "                        y_test = y_test * offset_test\n",
    "                        y_train = y_train * np.array(data_dict['train']['offset']).flatten()\n",
    "                    temp_results = compute_metrics(y_test, y_pred, np.mean(y_train), metrics)\n",
    "                    for metric in metrics:\n",
    "                        results[metric][test_fold, data_number] = temp_results[metric]\n",
    "                    results['time'][test_fold, data_number] = computing_time\n",
    "                    del M; gc.collect()\n",
    "            for metric in metrics+['time']:\n",
    "                pd.DataFrame(results[metric], columns=data_names).to_csv(f'{path_res}/{model_name}-{metric}-{experiment}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c21ef7",
   "metadata": {},
   "source": [
    "### H-LMMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe92590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "model_name = 'HLMMNN'\n",
    "# ---------------------------------\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_nodes in num_nodes_list:\n",
    "            experiment = f'lr{learning_rate}-batch{batch_size}-nodes{num_nodes[0]}'\n",
    "            results = {metric:np.zeros((n_folds, len(data_names))) for metric in metrics+['time']}\n",
    "            for data_number, data_name in enumerate(data_names):\n",
    "                data = pd.read_csv(f'{path_data}/{data_name}-prep.csv', dtype='float32', engine='pyarrow')        \n",
    "                n_clusters = np.unique(data['id']).shape[0]\n",
    "                n_features = 1+max([int(col_name[1:]) if 'x' in col_name else 0 for col_name in data.columns])\n",
    "                for test_fold in tqdm(range(n_folds), desc=data_name):\n",
    "                    valid_fold = (test_fold+1)//n_folds\n",
    "                    data_dict = {\n",
    "                        'train':data[-data['fold'].isin([valid_fold, test_fold])],\n",
    "                        'valid':data[data['fold'] == valid_fold],\n",
    "                        'test' :data[data['fold'] == test_fold],\n",
    "                    }\n",
    "                    for subset_name, subset in data_dict.items():\n",
    "                        z = np.array(subset['id'], dtype=np.int32)\n",
    "                        globals()[f'X_{subset_name}'] = np.array(subset[[f'x{i}' for i in range(n_features)]], dtype=np.float32)\n",
    "                        globals()[f'Z_{subset_name}'] = np.zeros((len(z), n_clusters), dtype=np.float32)\n",
    "                        globals()[f'Z_{subset_name}'][np.arange(len(z)), z] = 1\n",
    "                        globals()[f'y_{subset_name}'] = np.array(subset['y'], dtype=np.float32).reshape(-1,1)\n",
    "                    torch.cuda.empty_cache(); gc.collect()\n",
    "                    seed_everything()\n",
    "                    M = HMixNet(n_clusters, n_features, num_nodes, activation, device=device)            \n",
    "                    start_time = time.time()\n",
    "                    M.train_hlik([np.log(y_train+0.5), X_train, Z_train], [np.log(y_valid+0.5), X_valid, Z_valid],\n",
    "                            optimizer, learning_rate, batch_size, max_epochs, patience, sig2e_init, sig2u_init)\n",
    "                    computing_time = time.time() - start_time\n",
    "                    y_pred = M.predict(X_test, Z_test)\n",
    "                    if data_name == 'owls':\n",
    "                        offset_test = np.array(data_dict['test']['offset']).flatten()\n",
    "                        y_pred = y_pred * offset_test\n",
    "                        y_test = y_test * offset_test\n",
    "                        y_train = y_train * np.array(data_dict['train']['offset']).flatten()\n",
    "                    temp_results = compute_metrics(y_test, y_pred, np.mean(y_train), metrics)\n",
    "                    for metric in metrics:\n",
    "                        results[metric][test_fold, data_number] = temp_results[metric]\n",
    "                    results['time'][test_fold, data_number] = computing_time\n",
    "                    del M; gc.collect()\n",
    "            for metric in metrics+['time']:\n",
    "                pd.DataFrame(results[metric], columns=data_names).to_csv(f'{path_res}/{model_name}-{metric}-{experiment}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
