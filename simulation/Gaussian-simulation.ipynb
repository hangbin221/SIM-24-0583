{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbc901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, gc, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'source')))\n",
    "from HMixNetTorch import HMixNet, seed_everything\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04463dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.abspath('data')\n",
    "path_res  = os.path.abspath('results')\n",
    "n_repeats = 10\n",
    "n_clusters, cluster_size = 10000, 12\n",
    "cluster_size_train, cluster_size_valid, cluster_size_test = 8, 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_distributions = ['IND', 'AR1', 'AR2', 'SYM', 'MIX']\n",
    "random_effects_types = ['X-0.0']\n",
    "for random_effects_distribution in ['G', 'N', 'M']: # gamma, log-normal, mixture\n",
    "    for random_effects_variance in [1.0, 2.0]:\n",
    "        random_effects_types.append(f'{random_effects_distribution}-{random_effects_variance:.1f}')\n",
    "metrics = ['RMSP', 'RMD', 'R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 50\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 0.01\n",
    "batch_size = 1000\n",
    "num_nodes = [50, 25, 12]\n",
    "activation = torch.nn.LeakyReLU()\n",
    "max_epochs = 100\n",
    "patience = 5\n",
    "sig2u_init = 0.8\n",
    "sig2e_init = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721deef5",
   "metadata": {},
   "source": [
    "### Gaussian-NN(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "model_name = 'GNN-M'\n",
    "# ---------------------------------\n",
    "results = {metric:np.zeros((n_repeats*len(input_distributions), len(random_effects_types))) for metric in metrics+['time']}\n",
    "experiments = [f'{input_distribution}-{simulation_number}' for input_distribution in input_distributions for simulation_number in range(n_repeats)]\n",
    "is_conditional = False\n",
    "for k_re, random_effects_type in enumerate(random_effects_types):    \n",
    "    for k_in, input_distribution in enumerate(input_distributions):\n",
    "        for simulation_number in tqdm(range(n_repeats), desc=f'X: {input_distribution}, u: {random_effects_type}'):\n",
    "            data = pd.read_csv(f'{path_data}/data-{input_distribution}-{random_effects_type}-{simulation_number}.csv')\n",
    "            data = {\n",
    "                'train':data[data['number'].isin(range(cluster_size_train))],\n",
    "                'valid':data[data['number'].isin(range(cluster_size_train, cluster_size_train+cluster_size_valid))],\n",
    "                'test' :data[data['number'].isin(range(cluster_size_train+cluster_size_valid, cluster_size))],\n",
    "            }\n",
    "            for subset_name, subset in data.items():\n",
    "                z = np.array(subset['cluster'], dtype=np.int32)\n",
    "                globals()[f'y_{subset_name}'] = np.array(subset['y'], dtype=np.float32).reshape(-1,1)\n",
    "                globals()[f'X_{subset_name}'] = np.array(subset[[f'x{i}' for i in range(n_features)]], dtype=np.float32)\n",
    "                globals()[f'Z_{subset_name}'] = np.zeros((len(z), n_clusters), dtype=np.float32)\n",
    "                globals()[f'Z_{subset_name}'][np.arange(len(z)), z] = 1\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "            seed_everything()\n",
    "            M = HMixNet(n_clusters, n_features, num_nodes, activation, device=device)            \n",
    "            start_time = time.time()\n",
    "            M.train_clik([np.log(y_train+0.5), X_train, Z_train], [np.log(y_valid+0.5), X_valid, Z_valid], is_conditional,\n",
    "                    optimizer, learning_rate, batch_size, max_epochs, patience, sig2e_init)\n",
    "            computing_time = time.time() - start_time\n",
    "            y_pred = M.predict(X_test)\n",
    "            temp_results = compute_metrics(y_test, y_pred, np.mean(y_train), metrics)\n",
    "            for metric in metrics:\n",
    "                results[metric][(k_in*n_repeats+simulation_number), k_re] = temp_results[metric]\n",
    "            results['time'][(k_in*n_repeats+simulation_number), k_re] = computing_time            \n",
    "            del M; gc.collect()    \n",
    "for metric in metrics+['time']:\n",
    "    pd.DataFrame(results[metric], columns=random_effects_types, index=experiments).to_csv(f'{path_res}/{model_name}-{metric}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ff3d2",
   "metadata": {},
   "source": [
    "### Gaussian-NN(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "model_name = 'GNN-C'\n",
    "# ---------------------------------\n",
    "results = {metric:np.zeros((n_repeats*len(input_distributions), len(random_effects_types))) for metric in metrics+['time']}\n",
    "experiments = [f'{input_distribution}-{simulation_number}' for input_distribution in input_distributions for simulation_number in range(n_repeats)]\n",
    "is_conditional = True\n",
    "for k_re, random_effects_type in enumerate(random_effects_types):    \n",
    "    for k_in, input_distribution in enumerate(input_distributions):\n",
    "        for simulation_number in tqdm(range(n_repeats), desc=f'X: {input_distribution}, u: {random_effects_type}'):\n",
    "            data = pd.read_csv(f'{path_data}/data-{input_distribution}-{random_effects_type}-{simulation_number}.csv')\n",
    "            data = {\n",
    "                'train':data[data['number'].isin(range(cluster_size_train))],\n",
    "                'valid':data[data['number'].isin(range(cluster_size_train, cluster_size_train+cluster_size_valid))],\n",
    "                'test' :data[data['number'].isin(range(cluster_size_train+cluster_size_valid, cluster_size))],\n",
    "            }\n",
    "            for subset_name, subset in data.items():\n",
    "                z = np.array(subset['cluster'], dtype=np.int32)\n",
    "                globals()[f'y_{subset_name}'] = np.array(subset['y'], dtype=np.float32).reshape(-1,1)\n",
    "                globals()[f'X_{subset_name}'] = np.array(subset[[f'x{i}' for i in range(n_features)]], dtype=np.float32)\n",
    "                globals()[f'Z_{subset_name}'] = np.zeros((len(z), n_clusters), dtype=np.float32)\n",
    "                globals()[f'Z_{subset_name}'][np.arange(len(z)), z] = 1                \n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "            seed_everything()\n",
    "            M = HMixNet(n_clusters, n_features, num_nodes, activation, device=device)            \n",
    "            start_time = time.time()\n",
    "            M.train_clik([np.log(y_train+0.5), X_train, Z_train], [np.log(y_valid+0.5), X_valid, Z_valid], is_conditional,\n",
    "                    optimizer, learning_rate, batch_size, max_epochs, patience, sig2e_init)\n",
    "            computing_time = time.time() - start_time\n",
    "            y_pred = M.predict(X_test, Z_test)\n",
    "            temp_results = compute_metrics(y_test, y_pred, np.mean(y_train), metrics)\n",
    "            for metric in metrics:\n",
    "                results[metric][(k_in*n_repeats+simulation_number), k_re] = temp_results[metric]\n",
    "            results['time'][(k_in*n_repeats+simulation_number), k_re] = computing_time            \n",
    "            del M; gc.collect()    \n",
    "for metric in metrics+['time']:\n",
    "    pd.DataFrame(results[metric], columns=random_effects_types, index=experiments).to_csv(f'{path_res}/{model_name}-{metric}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863114cf",
   "metadata": {},
   "source": [
    "### H-LMMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "model_name = 'HLMMNN'\n",
    "# ---------------------------------\n",
    "results = {metric:np.zeros((n_repeats*len(input_distributions), len(random_effects_types))) for metric in metrics+['time']}\n",
    "experiments = [f'{input_distribution}-{simulation_number}' for input_distribution in input_distributions for simulation_number in range(n_repeats)]\n",
    "for k_re, random_effects_type in enumerate(random_effects_types):    \n",
    "    for k_in, input_distribution in enumerate(input_distributions):\n",
    "        for simulation_number in tqdm(range(n_repeats), desc=f'X: {input_distribution}, u: {random_effects_type}'):\n",
    "            data = pd.read_csv(f'{path_data}/data-{input_distribution}-{random_effects_type}-{simulation_number}.csv')\n",
    "            data = {\n",
    "                'train':data[data['number'].isin(range(cluster_size_train))],\n",
    "                'valid':data[data['number'].isin(range(cluster_size_train, cluster_size_train+cluster_size_valid))],\n",
    "                'test' :data[data['number'].isin(range(cluster_size_train+cluster_size_valid, cluster_size))],\n",
    "            }\n",
    "            for subset_name, subset in data.items():\n",
    "                z = np.array(subset['cluster'], dtype=np.int32)\n",
    "                globals()[f'y_{subset_name}'] = np.array(subset['y'], dtype=np.float32).reshape(-1,1)\n",
    "                globals()[f'X_{subset_name}'] = np.array(subset[[f'x{i}' for i in range(n_features)]], dtype=np.float32)\n",
    "                globals()[f'Z_{subset_name}'] = np.zeros((len(z), n_clusters), dtype=np.float32)\n",
    "                globals()[f'Z_{subset_name}'][np.arange(len(z)), z] = 1                \n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "            seed_everything()\n",
    "            M = HMixNet(n_clusters, n_features, num_nodes, activation, device=device)            \n",
    "            start_time = time.time()\n",
    "            M.train_hlik([np.log(y_train+0.5), X_train, Z_train], [np.log(y_valid+0.5), X_valid, Z_valid],\n",
    "                    optimizer, learning_rate, batch_size, max_epochs, patience, \n",
    "                    sig2e_init, sig2u_init)\n",
    "            computing_time = time.time() - start_time\n",
    "            y_pred = M.predict(X_test, Z_test)\n",
    "            temp_results = compute_metrics(y_test, y_pred, np.mean(y_train), metrics)\n",
    "            for metric in metrics:\n",
    "                results[metric][(k_in*n_repeats+simulation_number), k_re] = temp_results[metric]\n",
    "            results['time'][(k_in*n_repeats+simulation_number), k_re] = computing_time            \n",
    "            del M; gc.collect()\n",
    "for metric in metrics+['time']:\n",
    "    pd.DataFrame(results[metric], columns=random_effects_types, index=experiments).to_csv(f'{path_res}/{model_name}-{metric}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
