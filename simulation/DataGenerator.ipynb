{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import cholesky\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixture_lognormal(means, variances, size):\n",
    "    if isinstance(means, list): means = np.array(means)\n",
    "    if isinstance(variances, list): variances = np.array(variances)\n",
    "    if isinstance(means, (int, float)): means = np.array([float(means) for _ in range(variances.shape[0])])\n",
    "    if isinstance(variances, (int, float)): variances = np.array([float(variances) for _ in range(means.shape[0])])    \n",
    "    assert means.shape==variances.shape, \"Mismatch in length of means and variances\"\n",
    "    # covert means and variances of lognormal to those of normal\n",
    "    means_normal = np.log(means) - 0.5 * np.log(variances/means**2+1)\n",
    "    variances_normal = np.log(variances/means**2+1)\n",
    "    idx = np.random.randint(0, np.shape(means_normal), size)\n",
    "    means_array = np.array(means_normal)[idx]\n",
    "    stdvs_array = np.sqrt(np.array(variances_normal)[idx])    \n",
    "    data = np.exp(np.random.normal(means_array, stdvs_array))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_compound_symmetry(sample_size, n_features, rho=0.5, sigma=1.0):\n",
    "    cov_matrix = sigma**2 * ((1-rho) * np.eye(n_features) + rho * np.ones((n_features, n_features)))\n",
    "    L = cholesky(cov_matrix, lower=True)\n",
    "    X = np.random.normal(0, 1, (sample_size, n_features)) @ L.T\n",
    "    return X\n",
    "def generate_mixed_ar_cs(sample_size, n_features, ar=0.5, rho=0.5, sigma=1.0):\n",
    "    # Generate a mixture of AR(1) and Compound Symmetry data with binomially determined proportions\n",
    "    n_ar = np.random.binomial(sample_size, 0.5)  # Random proportion of AR(1) samples\n",
    "    n_cs = sample_size - n_ar\n",
    "    arma = ArmaProcess(ar=[1, -ar], ma=1)\n",
    "    X_ar = arma.generate_sample(nsample=(n_ar, n_features), axis=1)\n",
    "    X_cs = generate_compound_symmetry(n_cs, n_features, rho, sigma)    \n",
    "    X_mixed = np.vstack((X_ar, X_cs))\n",
    "    np.random.shuffle(X_mixed)  # Shuffle to mix AR(1) and CS samples\n",
    "    return X_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mean(beta, input_distribution, random_effects_distribution, random_effects_variance, n_clusters, cluster_size):    \n",
    "    n_features = 50\n",
    "    sample_size = n_clusters * cluster_size\n",
    "    beta = beta.reshape(-1,1)    \n",
    "    # generate X -------------------------------------------------------\n",
    "    if input_distribution.upper() == 'IND': # independent\n",
    "        X = np.random.normal(0, 1, (sample_size, 100))\n",
    "    elif input_distribution.upper() == 'AR1':\n",
    "        arma = ArmaProcess(ar=[1, -0.5], ma=1)\n",
    "        X = arma.generate_sample(nsample=(sample_size, 100), axis=1)\n",
    "    elif input_distribution.upper() == 'AR2':\n",
    "        arma = ArmaProcess(ar=[1, -0.5, -0.25], ma=1)\n",
    "        X = arma.generate_sample(nsample=(sample_size, 100), axis=1)\n",
    "    elif input_distribution.upper() == 'SYM': # compound symmetry\n",
    "        X = generate_compound_symmetry(sample_size, 100, rho=0.5)\n",
    "    elif input_distribution.upper() == 'MIX': # mixture of compound symmetry and AR1\n",
    "        X = generate_mixed_ar_cs(sample_size, 100, ar=0.5, rho=0.5)\n",
    "    else:\n",
    "        X = np.random.uniform(-np.pi/2, np.pi/2, (sample_size, 100))\n",
    "    data = pd.DataFrame(X, columns=[('x'+str(i)) for i in range(n_features)])\n",
    "    data['cluster'] = np.repeat(np.arange(n_clusters), cluster_size)\n",
    "    data['number'] = np.tile(np.arange(cluster_size), n_clusters)    \n",
    "    # generate u -------------------------------------------------------\n",
    "    if random_effects_distribution == 'X':\n",
    "        u = np.repeat(1., n_clusters)\n",
    "    elif random_effects_distribution == 'G': \n",
    "        u = np.random.gamma(1./random_effects_variance, random_effects_variance, n_clusters)\n",
    "    elif random_effects_distribution == 'N':\n",
    "        sig2 = np.log((1+np.sqrt(1+4*random_effects_variance))/2)\n",
    "        u = np.exp(np.random.normal(0., np.sqrt(sig2), n_clusters))        \n",
    "    elif random_effects_distribution == 'M':\n",
    "        means = [0.5, 1.5]\n",
    "        variances = [(4.*random_effects_variance-1.)/20., 9.*(4.*random_effects_variance-1.)/20.]\n",
    "        u = generate_mixture_lognormal(means, variances, n_clusters)\n",
    "    else: raise ValueError(f\"Unknown random effects distribution: {random_effects_distribution}\")\n",
    "    data['u'] = np.repeat(u, cluster_size)\n",
    "    # generate mu ------------------------------------------------------\n",
    "    data['mu']=np.array(data['u']).reshape(-1,1)*np.exp(\n",
    "        np.sin(X[:,:10])@beta + np.sin(X[:,20:30]*X[:,30:40])@beta\n",
    "        + np.cos(X[:,10:20])@beta + np.cos(X[:,30:40]*X[:,40:50])@beta\n",
    "    )\n",
    "    # ------------------------------------------------------------------\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_count_data(path, beta, input_distributions, random_effects_types, n_clusters, cluster_size, n_repeats):\n",
    "    sample_size = n_clusters*cluster_size\n",
    "    for random_effects_type in random_effects_types:\n",
    "        random_effects_distribution, random_effects_variance = random_effects_type.split('-')\n",
    "        for input_distribution in input_distributions:\n",
    "            for simulation_number in tqdm(range(n_repeats), desc=f'X: {input_distribution}, u: {random_effects_type}'):\n",
    "                np.random.seed(simulation_number)\n",
    "                data = generate_mean(beta, input_distribution, random_effects_distribution, float(random_effects_variance), n_clusters, cluster_size)\n",
    "                data['y'] = np.random.poisson(data['mu'], data['mu'].shape)                \n",
    "                file_name = f'{path}/data-{input_distribution}-{random_effects_type}-{simulation_number}.csv'\n",
    "                data.to_csv(file_name, index=False)\n",
    "                del data; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.abspath('data')\n",
    "n_repeats = 10\n",
    "n_clusters, cluster_size = 10000, 12\n",
    "# ------------------------------------------------------------------\n",
    "beta = 0.02*np.array(list(np.arange(-5,0)) + list(np.arange(1,6)))\n",
    "# ------------------------------------------------------------------\n",
    "input_distributions = ['IND', 'AR1', 'AR2', 'SYM', 'MIX']\n",
    "random_effects_types = ['X-0.0']\n",
    "for random_effects_distribution in ['G', 'N', 'M']: # gamma, log-normal, mixture\n",
    "    for random_effects_variance in [1.0, 2.0]:\n",
    "        random_effects_types.append(f'{random_effects_distribution}-{random_effects_variance:.1f}')\n",
    "generate_count_data(path_data, beta, input_distributions, random_effects_types, n_clusters, cluster_size, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'source')))\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_res  = os.path.abspath('results')\n",
    "n_clusters, cluster_size = 10000, 12\n",
    "cluster_size_train, cluster_size_valid, cluster_size_test = 8, 2, 2\n",
    "metrics = ['RMSP', 'RMD', 'R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "model_name = 'true'\n",
    "# ------------------------------------------------------------------\n",
    "results = {metric:np.zeros((n_repeats*len(input_distributions), len(random_effects_types))) for metric in metrics+['time']}\n",
    "experiments = [f'{input_distribution}-{simulation_number}' for input_distribution in input_distributions for simulation_number in range(n_repeats)]\n",
    "for k_re, random_effects_type in enumerate(random_effects_types):    \n",
    "    for k_in, input_distribution in enumerate(input_distributions):\n",
    "        for simulation_number in tqdm(range(n_repeats), desc=f'X: {input_distribution}, u: {random_effects_type}'):\n",
    "            data = pd.read_csv(f'{path_data}/data-{input_distribution}-{random_effects_type}-{simulation_number}.csv')\n",
    "            data_test = data[data['number'].isin(range(cluster_size_train+cluster_size_valid, cluster_size))]\n",
    "            y_test = np.array(data_test['y'],  dtype=np.float32)\n",
    "            y_pred = np.array(data_test['mu'], dtype=np.float32)\n",
    "            temp_results = compute_metrics(y_test, y_pred, metrics)\n",
    "            for metric in metrics:\n",
    "                results[metric][(k_in*n_repeats+simulation_number), k_re] = temp_results[metric]\n",
    "            results['time'][(k_in*n_repeats+simulation_number), k_re] = 0.\n",
    "    for metric in metrics+['time']:\n",
    "        print(f'{metric.upper()}: {\"{:.3f}\".format(np.mean(results[metric][:, k_re]))} ({\"{:.3f}\".format(np.std(results[metric][:, k_re]))})')\n",
    "for metric in metrics+['time']:\n",
    "    pd.DataFrame(results[metric], columns=random_effects_types, index=experiments).to_csv(f'{path_res}/{model_name}-{metric}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
